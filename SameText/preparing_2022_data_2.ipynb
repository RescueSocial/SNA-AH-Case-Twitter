{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c594edd3",
   "metadata": {},
   "source": [
    "# Social Network Analysis - Amber Heard Case - Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f17b15",
   "metadata": {},
   "source": [
    "## Preparing Data Set - P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a0ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Leap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Leap\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "import re\n",
    "import seaborn as sb\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import plotly.io as pio\n",
    "from helpers import *\n",
    "\n",
    "pio.renderers\n",
    "# pio.renderers.default = \"svg\"\n",
    "svg_renderer = pio.renderers[\"svg\"]\n",
    "svg_renderer.width = 950\n",
    "svg_renderer.height = 550\n",
    "\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import ast\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffedda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../twitter_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968201ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022 = [_ for _ in os.listdir(data_path) if \"2022\" in _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e0e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-2022 Twitter all_quotes retweets Amber Heard Timeline_Data.csv',\n",
       " '2022 Tweets_Metrics.csv',\n",
       " '2022 Twitter Accounts Jan-April_Amber Heard Data.csv',\n",
       " '2022 Twitter daily_creation Jan-April_Amber Heard Data.csv',\n",
       " '2022 Twitter Tweets Jan-April_Amber Heard Data.csv',\n",
       " '2022 Twitter Tweets_lite Jan-April_Amber Heard Data.csv',\n",
       " '2022 Twitter users_created_in_2022_Jan-April_Amber Heard Data.csv',\n",
       " '2022_prepared_tweets.csv',\n",
       " 'Twitter 2017-2022 all_comments on Amber Heard Profile.csv',\n",
       " 'Twitter 2017-2022 all_comments on Amber Heard Profile.json',\n",
       " 'Twitter comments_2022 on Profile Amber Heard.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e2cab",
   "metadata": {},
   "source": [
    "## Load Twitter Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69c6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2022_prepared = pd.read_csv(data_path+\"2022_prepared_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f275255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2022_prepared[\"created_at\"] = pd.to_datetime(df_tweets_2022_prepared[\"created_at\"])\n",
    "df_tweets_2022_prepared[\"user.created_at\"] = pd.to_datetime(df_tweets_2022_prepared[\"user.created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b01076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2022_prepared.drop(columns=[\"user.description\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbbec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2022_prepared.rename(\n",
    "    columns={\n",
    "        \"id_str\": \"id\",\n",
    "        \"user.id_str\": \"user_id\",\n",
    "        \"user.screen_name\": \"user_name\",\n",
    "        \"user.created_at\": \"user_created_at\",\n",
    "        \"tokens\": \"text_tokens\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "446f3413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Head\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>mentions</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>n_hashtags</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>user_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1477504983130116096</td>\n",
       "      <td>2022-01-02 05:00:13+00:00</td>\n",
       "      <td>1.149795e+08</td>\n",
       "      <td>seano999</td>\n",
       "      <td>2010-02-17 06:20:14+00:00</td>\n",
       "      <td>['la77465262', 'Melinda15199317', 'Dior']</td>\n",
       "      <td>3</td>\n",
       "      <td>['JohnnyDepp']</td>\n",
       "      <td>1</td>\n",
       "      <td>so why is  only bringing a civil case against ...</td>\n",
       "      <td>['bringing', 'civil', 'case', 'amber', 'heard'...</td>\n",
       "      <td>young guy, varied interests. socialist. europe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1477503751716065280</td>\n",
       "      <td>2022-01-02 04:55:19+00:00</td>\n",
       "      <td>1.426227e+18</td>\n",
       "      <td>WonderWilson18</td>\n",
       "      <td>2021-08-13 17:00:36+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>only thing i want them to leave alone is the f...</td>\n",
       "      <td>['thing', 'leave', 'alone', 'first', 'wonder',...</td>\n",
       "      <td>so fuck your rules man your favorite k2, avril...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                created_at       user_id  \\\n",
       "0  1477504983130116096 2022-01-02 05:00:13+00:00  1.149795e+08   \n",
       "1  1477503751716065280 2022-01-02 04:55:19+00:00  1.426227e+18   \n",
       "\n",
       "        user_name           user_created_at  \\\n",
       "0        seano999 2010-02-17 06:20:14+00:00   \n",
       "1  WonderWilson18 2021-08-13 17:00:36+00:00   \n",
       "\n",
       "                                    mentions  n_mentions        hashtags  \\\n",
       "0  ['la77465262', 'Melinda15199317', 'Dior']           3  ['JohnnyDepp']   \n",
       "1                                         []           0              []   \n",
       "\n",
       "   n_hashtags                                         clean_text  \\\n",
       "0           1  so why is  only bringing a civil case against ...   \n",
       "1           0  only thing i want them to leave alone is the f...   \n",
       "\n",
       "                                         text_tokens  \\\n",
       "0  ['bringing', 'civil', 'case', 'amber', 'heard'...   \n",
       "1  ['thing', 'leave', 'alone', 'first', 'wonder',...   \n",
       "\n",
       "                                    user_description  \n",
       "0  young guy, varied interests. socialist. europe...  \n",
       "1  so fuck your rules man your favorite k2, avril...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "Data Shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The data has 573780 rows and 12 columns'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "Columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'created_at',\n",
       " 'user_id',\n",
       " 'user_name',\n",
       " 'user_created_at',\n",
       " 'mentions',\n",
       " 'n_mentions',\n",
       " 'hashtags',\n",
       " 'n_hashtags',\n",
       " 'clean_text',\n",
       " 'text_tokens',\n",
       " 'user_description']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "Columns Must be Dropped (ALL NULLS)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "Columns Must be Dropped (HAS ONLY ONE UNIQUE VALUE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "Column Data Type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                                                       int\n",
       "created_at          pandas._libs.tslibs.timestamps.Timestamp\n",
       "user_id                                                float\n",
       "user_name                                                str\n",
       "user_created_at     pandas._libs.tslibs.timestamps.Timestamp\n",
       "mentions                                                 str\n",
       "n_mentions                                               int\n",
       "hashtags                                                 str\n",
       "n_hashtags                                               int\n",
       "clean_text                                               str\n",
       "text_tokens                                              str\n",
       "user_description                                         str\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "Number of Nulls in Each Column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_description    119082\n",
       "clean_text           58134\n",
       "text_tokens          58134\n",
       "user_id              51528\n",
       "user_name            51528\n",
       "user_created_at      51528\n",
       "created_at               2\n",
       "id                       0\n",
       "mentions                 0\n",
       "n_mentions               0\n",
       "hashtags                 0\n",
       "n_hashtags               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "Percentge of Nulls in Each Column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_description    0.207539\n",
       "clean_text          0.101318\n",
       "text_tokens         0.101318\n",
       "user_id             0.089804\n",
       "user_name           0.089804\n",
       "user_created_at     0.089804\n",
       "created_at          0.000003\n",
       "id                  0.000000\n",
       "mentions            0.000000\n",
       "n_mentions          0.000000\n",
       "hashtags            0.000000\n",
       "n_hashtags          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n",
      "Numeric Columns' Staticts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>n_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.222520e+05</td>\n",
       "      <td>573780.000000</td>\n",
       "      <td>573780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.100235e+17</td>\n",
       "      <td>0.339529</td>\n",
       "      <td>1.035345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.337171e+17</td>\n",
       "      <td>0.964897</td>\n",
       "      <td>1.588022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.968000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.470993e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.302652e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.325802e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.519822e+18</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id     n_mentions     n_hashtags\n",
       "count  5.222520e+05  573780.000000  573780.000000\n",
       "mean   7.100235e+17       0.339529       1.035345\n",
       "std    6.337171e+17       0.964897       1.588022\n",
       "min    1.968000e+03       0.000000       0.000000\n",
       "25%    4.470993e+08       0.000000       0.000000\n",
       "50%    9.302652e+17       0.000000       0.000000\n",
       "75%    1.325802e+18       0.000000       1.000000\n",
       "max    1.519822e+18      50.000000      23.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_investigation(df_tweets_2022_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcf1d5",
   "metadata": {},
   "source": [
    "**10 % of text (tweets) contains only emojis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c54c6",
   "metadata": {},
   "source": [
    "## User Desription into Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae4e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stop_words = []\n",
    "for lang in stopwords.fileids():\n",
    "    all_stop_words.append(stopwords.words(lang))\n",
    "all_stop_words = [item for sublist in all_stop_words for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "818192d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> list:\n",
    "    if str(text) == \"nan\":\n",
    "        return None\n",
    "    else:\n",
    "        return [i for i in [i for i in word_tokenize(text) if i not in all_stop_words] if i.isalnum()]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cb137d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2022_prepared[\"user_description\"] = np.where(\n",
    "    df_tweets_2022_prepared.user_description == \"\",\n",
    "    np.nan,\n",
    "    df_tweets_2022_prepared.user_description,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4212a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1071.531247138977 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "df_tweets_2022_prepared[\"user_description_tokens\"] = df_tweets_2022_prepared.user_description.apply(lambda x: tokenize(str(x)))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50c4f66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>mentions</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>n_hashtags</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_description_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1477504983130116096</td>\n",
       "      <td>2022-01-02 05:00:13+00:00</td>\n",
       "      <td>1.149795e+08</td>\n",
       "      <td>seano999</td>\n",
       "      <td>2010-02-17 06:20:14+00:00</td>\n",
       "      <td>['la77465262', 'Melinda15199317', 'Dior']</td>\n",
       "      <td>3</td>\n",
       "      <td>['JohnnyDepp']</td>\n",
       "      <td>1</td>\n",
       "      <td>so why is  only bringing a civil case against ...</td>\n",
       "      <td>['bringing', 'civil', 'case', 'amber', 'heard'...</td>\n",
       "      <td>young guy, varied interests. socialist. europe...</td>\n",
       "      <td>[young, guy, varied, interests, socialist, eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1477503751716065280</td>\n",
       "      <td>2022-01-02 04:55:19+00:00</td>\n",
       "      <td>1.426227e+18</td>\n",
       "      <td>WonderWilson18</td>\n",
       "      <td>2021-08-13 17:00:36+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>only thing i want them to leave alone is the f...</td>\n",
       "      <td>['thing', 'leave', 'alone', 'first', 'wonder',...</td>\n",
       "      <td>so fuck your rules man your favorite k2, avril...</td>\n",
       "      <td>[fuck, rules, favorite, k2, avril, lavigne, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1477499814719983617</td>\n",
       "      <td>2022-01-02 04:39:41+00:00</td>\n",
       "      <td>1.427359e+18</td>\n",
       "      <td>StevenJCurry</td>\n",
       "      <td>2021-08-16 19:58:03+00:00</td>\n",
       "      <td>['soldierboy43001', 'ZakReckless']</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah but snyder isn't involved in the flash so...</td>\n",
       "      <td>['yeah', 'snyder', 'involved', 'flash', 'would...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1477497740498292738</td>\n",
       "      <td>2022-01-02 04:31:26+00:00</td>\n",
       "      <td>1.354477e+18</td>\n",
       "      <td>Vincent72516869</td>\n",
       "      <td>2021-01-27 17:11:08+00:00</td>\n",
       "      <td>['IIMissMax', 'bg98021', 'GerberKawasaki']</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>you forgot he hook up with amber heard . i am ...</td>\n",
       "      <td>['forgot', 'hook', 'amber', 'heard', 'sure', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1477496477484212225</td>\n",
       "      <td>2022-01-02 04:26:25+00:00</td>\n",
       "      <td>1.076943e+18</td>\n",
       "      <td>YoonJaysSimp</td>\n",
       "      <td>2018-12-23 20:50:49+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>i never seen aquaman nor will i because amber ...</td>\n",
       "      <td>['never', 'seen', 'aquaman', 'amber', 'heard']</td>\n",
       "      <td>bl content * anime * manga * manhwa * nsfw * s...</td>\n",
       "      <td>[bl, content, anime, manga, manhwa, nsfw, simm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573775</th>\n",
       "      <td>1515569901158600704</td>\n",
       "      <td>2022-04-17 05:56:37+00:00</td>\n",
       "      <td>2.701354e+07</td>\n",
       "      <td>GhelSandra</td>\n",
       "      <td>2009-03-27 14:25:52+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>gender card pulled out. they are now spinning ...</td>\n",
       "      <td>['gender', 'card', 'pulled', 'spinning', 'make...</td>\n",
       "      <td>tomasino est 2000something art educator.person...</td>\n",
       "      <td>[tomasino, 2000something, art, sayaka, akimoto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573776</th>\n",
       "      <td>1515569890391961601</td>\n",
       "      <td>2022-04-17 05:56:34+00:00</td>\n",
       "      <td>1.418420e+18</td>\n",
       "      <td>lilithrising_</td>\n",
       "      <td>2021-07-23 03:59:18+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>amber heard is a libra moon. ive known a few l...</td>\n",
       "      <td>['amber', 'heard', 'libra', 'moon', 'ive', 'kn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573777</th>\n",
       "      <td>1515569612686970883</td>\n",
       "      <td>2022-04-17 05:55:28+00:00</td>\n",
       "      <td>3.303069e+09</td>\n",
       "      <td>CJMoss007</td>\n",
       "      <td>2015-08-01 07:03:17+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['JusticeForJohnnyDepp', 'JusticeForJohnnyDepp...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#justiceforjohnnydepp</td>\n",
       "      <td>[justiceforjohnnydepp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573778</th>\n",
       "      <td>1515569604818575368</td>\n",
       "      <td>2022-04-17 05:55:26+00:00</td>\n",
       "      <td>1.319471e+18</td>\n",
       "      <td>Jankem69420</td>\n",
       "      <td>2020-10-23 02:50:36+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>amber heard is dating eve fartlow, chelsea man...</td>\n",
       "      <td>['amber', 'heard', 'dating', 'eve', 'fartlow',...</td>\n",
       "      <td>''virtue-signalling geopolitically ignorant ca...</td>\n",
       "      <td>[geopolitically, ignorant, cartoon, mouse, lam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573779</th>\n",
       "      <td>1515569491513589763</td>\n",
       "      <td>2022-04-17 05:54:59+00:00</td>\n",
       "      <td>4.194755e+09</td>\n",
       "      <td>mg_violette</td>\n",
       "      <td>2015-11-15 15:11:09+00:00</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['JohnnyDepp', 'JusticeForJohnnyDepp']</td>\n",
       "      <td>2</td>\n",
       "      <td>is and always will be a gentleman. yes, he wro...</td>\n",
       "      <td>['always', 'gentleman', 'yes', 'wrote', 'nice'...</td>\n",
       "      <td>author of the saga \"the guardian angel of the ...</td>\n",
       "      <td>[author, saga, guardian, angel, demon, book, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573780 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                created_at       user_id  \\\n",
       "0       1477504983130116096 2022-01-02 05:00:13+00:00  1.149795e+08   \n",
       "1       1477503751716065280 2022-01-02 04:55:19+00:00  1.426227e+18   \n",
       "2       1477499814719983617 2022-01-02 04:39:41+00:00  1.427359e+18   \n",
       "3       1477497740498292738 2022-01-02 04:31:26+00:00  1.354477e+18   \n",
       "4       1477496477484212225 2022-01-02 04:26:25+00:00  1.076943e+18   \n",
       "...                     ...                       ...           ...   \n",
       "573775  1515569901158600704 2022-04-17 05:56:37+00:00  2.701354e+07   \n",
       "573776  1515569890391961601 2022-04-17 05:56:34+00:00  1.418420e+18   \n",
       "573777  1515569612686970883 2022-04-17 05:55:28+00:00  3.303069e+09   \n",
       "573778  1515569604818575368 2022-04-17 05:55:26+00:00  1.319471e+18   \n",
       "573779  1515569491513589763 2022-04-17 05:54:59+00:00  4.194755e+09   \n",
       "\n",
       "              user_name           user_created_at  \\\n",
       "0              seano999 2010-02-17 06:20:14+00:00   \n",
       "1        WonderWilson18 2021-08-13 17:00:36+00:00   \n",
       "2          StevenJCurry 2021-08-16 19:58:03+00:00   \n",
       "3       Vincent72516869 2021-01-27 17:11:08+00:00   \n",
       "4          YoonJaysSimp 2018-12-23 20:50:49+00:00   \n",
       "...                 ...                       ...   \n",
       "573775       GhelSandra 2009-03-27 14:25:52+00:00   \n",
       "573776    lilithrising_ 2021-07-23 03:59:18+00:00   \n",
       "573777        CJMoss007 2015-08-01 07:03:17+00:00   \n",
       "573778      Jankem69420 2020-10-23 02:50:36+00:00   \n",
       "573779      mg_violette 2015-11-15 15:11:09+00:00   \n",
       "\n",
       "                                          mentions  n_mentions  \\\n",
       "0        ['la77465262', 'Melinda15199317', 'Dior']           3   \n",
       "1                                               []           0   \n",
       "2               ['soldierboy43001', 'ZakReckless']           2   \n",
       "3       ['IIMissMax', 'bg98021', 'GerberKawasaki']           3   \n",
       "4                                               []           0   \n",
       "...                                            ...         ...   \n",
       "573775                                          []           0   \n",
       "573776                                          []           0   \n",
       "573777                                          []           0   \n",
       "573778                                          []           0   \n",
       "573779                                          []           0   \n",
       "\n",
       "                                                 hashtags  n_hashtags  \\\n",
       "0                                          ['JohnnyDepp']           1   \n",
       "1                                                      []           0   \n",
       "2                                                      []           0   \n",
       "3                                                      []           0   \n",
       "4                                                      []           0   \n",
       "...                                                   ...         ...   \n",
       "573775                                                 []           0   \n",
       "573776                                                 []           0   \n",
       "573777  ['JusticeForJohnnyDepp', 'JusticeForJohnnyDepp...           2   \n",
       "573778                                                 []           0   \n",
       "573779             ['JohnnyDepp', 'JusticeForJohnnyDepp']           2   \n",
       "\n",
       "                                               clean_text  \\\n",
       "0       so why is  only bringing a civil case against ...   \n",
       "1       only thing i want them to leave alone is the f...   \n",
       "2       yeah but snyder isn't involved in the flash so...   \n",
       "3       you forgot he hook up with amber heard . i am ...   \n",
       "4       i never seen aquaman nor will i because amber ...   \n",
       "...                                                   ...   \n",
       "573775  gender card pulled out. they are now spinning ...   \n",
       "573776  amber heard is a libra moon. ive known a few l...   \n",
       "573777                                                NaN   \n",
       "573778  amber heard is dating eve fartlow, chelsea man...   \n",
       "573779  is and always will be a gentleman. yes, he wro...   \n",
       "\n",
       "                                              text_tokens  \\\n",
       "0       ['bringing', 'civil', 'case', 'amber', 'heard'...   \n",
       "1       ['thing', 'leave', 'alone', 'first', 'wonder',...   \n",
       "2       ['yeah', 'snyder', 'involved', 'flash', 'would...   \n",
       "3       ['forgot', 'hook', 'amber', 'heard', 'sure', '...   \n",
       "4          ['never', 'seen', 'aquaman', 'amber', 'heard']   \n",
       "...                                                   ...   \n",
       "573775  ['gender', 'card', 'pulled', 'spinning', 'make...   \n",
       "573776  ['amber', 'heard', 'libra', 'moon', 'ive', 'kn...   \n",
       "573777                                                NaN   \n",
       "573778  ['amber', 'heard', 'dating', 'eve', 'fartlow',...   \n",
       "573779  ['always', 'gentleman', 'yes', 'wrote', 'nice'...   \n",
       "\n",
       "                                         user_description  \\\n",
       "0       young guy, varied interests. socialist. europe...   \n",
       "1       so fuck your rules man your favorite k2, avril...   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4       bl content * anime * manga * manhwa * nsfw * s...   \n",
       "...                                                   ...   \n",
       "573775  tomasino est 2000something art educator.person...   \n",
       "573776                                                NaN   \n",
       "573777                              #justiceforjohnnydepp   \n",
       "573778  ''virtue-signalling geopolitically ignorant ca...   \n",
       "573779  author of the saga \"the guardian angel of the ...   \n",
       "\n",
       "                                  user_description_tokens  \n",
       "0       [young, guy, varied, interests, socialist, eur...  \n",
       "1       [fuck, rules, favorite, k2, avril, lavigne, wo...  \n",
       "2                                                    None  \n",
       "3                                                    None  \n",
       "4       [bl, content, anime, manga, manhwa, nsfw, simm...  \n",
       "...                                                   ...  \n",
       "573775  [tomasino, 2000something, art, sayaka, akimoto...  \n",
       "573776                                               None  \n",
       "573777                             [justiceforjohnnydepp]  \n",
       "573778  [geopolitically, ignorant, cartoon, mouse, lam...  \n",
       "573779  [author, saga, guardian, angel, demon, book, a...  \n",
       "\n",
       "[573780 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_2022_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81620be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'created_at', 'user_id', 'user_name', 'user_created_at',\n",
       "       'mentions', 'n_mentions', 'hashtags', 'n_hashtags', 'clean_text',\n",
       "       'text_tokens', 'user_description', 'user_description_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_2022_prepared.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94570414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2022_prepared = df_tweets_2022_prepared[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"created_at\",\n",
    "        \"clean_text\",\n",
    "        \"text_tokens\",\n",
    "        \"mentions\",\n",
    "        \"n_mentions\",\n",
    "        \"hashtags\",\n",
    "        \"n_hashtags\",\n",
    "        \"user_id\",\n",
    "        \"user_name\",\n",
    "        \"user_created_at\",\n",
    "        \"user_description\",\n",
    "        \"user_description_tokens\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c741ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    if tokens is None:\n",
    "        return None\n",
    "    else:\n",
    "        return [i for i in tokens if i not in all_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f191c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2022_prepared[\"user_description_tokens\"] = df_tweets_2022_prepared[\n",
    "    \"user_description_tokens\"\n",
    "].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b49af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_tokens</th>\n",
       "      <th>mentions</th>\n",
       "      <th>n_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>n_hashtags</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_description_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1477504983130116096</td>\n",
       "      <td>2022-01-02 05:00:13+00:00</td>\n",
       "      <td>so why is  only bringing a civil case against ...</td>\n",
       "      <td>['bringing', 'civil', 'case', 'amber', 'heard'...</td>\n",
       "      <td>['la77465262', 'Melinda15199317', 'Dior']</td>\n",
       "      <td>3</td>\n",
       "      <td>['JohnnyDepp']</td>\n",
       "      <td>1</td>\n",
       "      <td>1.149795e+08</td>\n",
       "      <td>seano999</td>\n",
       "      <td>2010-02-17 06:20:14+00:00</td>\n",
       "      <td>young guy, varied interests. socialist. europe...</td>\n",
       "      <td>[young, guy, varied, interests, socialist, eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1477503751716065280</td>\n",
       "      <td>2022-01-02 04:55:19+00:00</td>\n",
       "      <td>only thing i want them to leave alone is the f...</td>\n",
       "      <td>['thing', 'leave', 'alone', 'first', 'wonder',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.426227e+18</td>\n",
       "      <td>WonderWilson18</td>\n",
       "      <td>2021-08-13 17:00:36+00:00</td>\n",
       "      <td>so fuck your rules man your favorite k2, avril...</td>\n",
       "      <td>[fuck, rules, favorite, k2, avril, lavigne, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1477499814719983617</td>\n",
       "      <td>2022-01-02 04:39:41+00:00</td>\n",
       "      <td>yeah but snyder isn't involved in the flash so...</td>\n",
       "      <td>['yeah', 'snyder', 'involved', 'flash', 'would...</td>\n",
       "      <td>['soldierboy43001', 'ZakReckless']</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.427359e+18</td>\n",
       "      <td>StevenJCurry</td>\n",
       "      <td>2021-08-16 19:58:03+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1477497740498292738</td>\n",
       "      <td>2022-01-02 04:31:26+00:00</td>\n",
       "      <td>you forgot he hook up with amber heard . i am ...</td>\n",
       "      <td>['forgot', 'hook', 'amber', 'heard', 'sure', '...</td>\n",
       "      <td>['IIMissMax', 'bg98021', 'GerberKawasaki']</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.354477e+18</td>\n",
       "      <td>Vincent72516869</td>\n",
       "      <td>2021-01-27 17:11:08+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1477496477484212225</td>\n",
       "      <td>2022-01-02 04:26:25+00:00</td>\n",
       "      <td>i never seen aquaman nor will i because amber ...</td>\n",
       "      <td>['never', 'seen', 'aquaman', 'amber', 'heard']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.076943e+18</td>\n",
       "      <td>YoonJaysSimp</td>\n",
       "      <td>2018-12-23 20:50:49+00:00</td>\n",
       "      <td>bl content * anime * manga * manhwa * nsfw * s...</td>\n",
       "      <td>[bl, content, anime, manga, manhwa, nsfw, simm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573775</th>\n",
       "      <td>1515569901158600704</td>\n",
       "      <td>2022-04-17 05:56:37+00:00</td>\n",
       "      <td>gender card pulled out. they are now spinning ...</td>\n",
       "      <td>['gender', 'card', 'pulled', 'spinning', 'make...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2.701354e+07</td>\n",
       "      <td>GhelSandra</td>\n",
       "      <td>2009-03-27 14:25:52+00:00</td>\n",
       "      <td>tomasino est 2000something art educator.person...</td>\n",
       "      <td>[tomasino, 2000something, art, sayaka, akimoto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573776</th>\n",
       "      <td>1515569890391961601</td>\n",
       "      <td>2022-04-17 05:56:34+00:00</td>\n",
       "      <td>amber heard is a libra moon. ive known a few l...</td>\n",
       "      <td>['amber', 'heard', 'libra', 'moon', 'ive', 'kn...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.418420e+18</td>\n",
       "      <td>lilithrising_</td>\n",
       "      <td>2021-07-23 03:59:18+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573777</th>\n",
       "      <td>1515569612686970883</td>\n",
       "      <td>2022-04-17 05:55:28+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['JusticeForJohnnyDepp', 'JusticeForJohnnyDepp...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.303069e+09</td>\n",
       "      <td>CJMoss007</td>\n",
       "      <td>2015-08-01 07:03:17+00:00</td>\n",
       "      <td>#justiceforjohnnydepp</td>\n",
       "      <td>[justiceforjohnnydepp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573778</th>\n",
       "      <td>1515569604818575368</td>\n",
       "      <td>2022-04-17 05:55:26+00:00</td>\n",
       "      <td>amber heard is dating eve fartlow, chelsea man...</td>\n",
       "      <td>['amber', 'heard', 'dating', 'eve', 'fartlow',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.319471e+18</td>\n",
       "      <td>Jankem69420</td>\n",
       "      <td>2020-10-23 02:50:36+00:00</td>\n",
       "      <td>''virtue-signalling geopolitically ignorant ca...</td>\n",
       "      <td>[geopolitically, ignorant, cartoon, mouse, lam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573779</th>\n",
       "      <td>1515569491513589763</td>\n",
       "      <td>2022-04-17 05:54:59+00:00</td>\n",
       "      <td>is and always will be a gentleman. yes, he wro...</td>\n",
       "      <td>['always', 'gentleman', 'yes', 'wrote', 'nice'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>['JohnnyDepp', 'JusticeForJohnnyDepp']</td>\n",
       "      <td>2</td>\n",
       "      <td>4.194755e+09</td>\n",
       "      <td>mg_violette</td>\n",
       "      <td>2015-11-15 15:11:09+00:00</td>\n",
       "      <td>author of the saga \"the guardian angel of the ...</td>\n",
       "      <td>[author, saga, guardian, angel, demon, book, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573780 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                created_at  \\\n",
       "0       1477504983130116096 2022-01-02 05:00:13+00:00   \n",
       "1       1477503751716065280 2022-01-02 04:55:19+00:00   \n",
       "2       1477499814719983617 2022-01-02 04:39:41+00:00   \n",
       "3       1477497740498292738 2022-01-02 04:31:26+00:00   \n",
       "4       1477496477484212225 2022-01-02 04:26:25+00:00   \n",
       "...                     ...                       ...   \n",
       "573775  1515569901158600704 2022-04-17 05:56:37+00:00   \n",
       "573776  1515569890391961601 2022-04-17 05:56:34+00:00   \n",
       "573777  1515569612686970883 2022-04-17 05:55:28+00:00   \n",
       "573778  1515569604818575368 2022-04-17 05:55:26+00:00   \n",
       "573779  1515569491513589763 2022-04-17 05:54:59+00:00   \n",
       "\n",
       "                                               clean_text  \\\n",
       "0       so why is  only bringing a civil case against ...   \n",
       "1       only thing i want them to leave alone is the f...   \n",
       "2       yeah but snyder isn't involved in the flash so...   \n",
       "3       you forgot he hook up with amber heard . i am ...   \n",
       "4       i never seen aquaman nor will i because amber ...   \n",
       "...                                                   ...   \n",
       "573775  gender card pulled out. they are now spinning ...   \n",
       "573776  amber heard is a libra moon. ive known a few l...   \n",
       "573777                                                NaN   \n",
       "573778  amber heard is dating eve fartlow, chelsea man...   \n",
       "573779  is and always will be a gentleman. yes, he wro...   \n",
       "\n",
       "                                              text_tokens  \\\n",
       "0       ['bringing', 'civil', 'case', 'amber', 'heard'...   \n",
       "1       ['thing', 'leave', 'alone', 'first', 'wonder',...   \n",
       "2       ['yeah', 'snyder', 'involved', 'flash', 'would...   \n",
       "3       ['forgot', 'hook', 'amber', 'heard', 'sure', '...   \n",
       "4          ['never', 'seen', 'aquaman', 'amber', 'heard']   \n",
       "...                                                   ...   \n",
       "573775  ['gender', 'card', 'pulled', 'spinning', 'make...   \n",
       "573776  ['amber', 'heard', 'libra', 'moon', 'ive', 'kn...   \n",
       "573777                                                NaN   \n",
       "573778  ['amber', 'heard', 'dating', 'eve', 'fartlow',...   \n",
       "573779  ['always', 'gentleman', 'yes', 'wrote', 'nice'...   \n",
       "\n",
       "                                          mentions  n_mentions  \\\n",
       "0        ['la77465262', 'Melinda15199317', 'Dior']           3   \n",
       "1                                               []           0   \n",
       "2               ['soldierboy43001', 'ZakReckless']           2   \n",
       "3       ['IIMissMax', 'bg98021', 'GerberKawasaki']           3   \n",
       "4                                               []           0   \n",
       "...                                            ...         ...   \n",
       "573775                                          []           0   \n",
       "573776                                          []           0   \n",
       "573777                                          []           0   \n",
       "573778                                          []           0   \n",
       "573779                                          []           0   \n",
       "\n",
       "                                                 hashtags  n_hashtags  \\\n",
       "0                                          ['JohnnyDepp']           1   \n",
       "1                                                      []           0   \n",
       "2                                                      []           0   \n",
       "3                                                      []           0   \n",
       "4                                                      []           0   \n",
       "...                                                   ...         ...   \n",
       "573775                                                 []           0   \n",
       "573776                                                 []           0   \n",
       "573777  ['JusticeForJohnnyDepp', 'JusticeForJohnnyDepp...           2   \n",
       "573778                                                 []           0   \n",
       "573779             ['JohnnyDepp', 'JusticeForJohnnyDepp']           2   \n",
       "\n",
       "             user_id        user_name           user_created_at  \\\n",
       "0       1.149795e+08         seano999 2010-02-17 06:20:14+00:00   \n",
       "1       1.426227e+18   WonderWilson18 2021-08-13 17:00:36+00:00   \n",
       "2       1.427359e+18     StevenJCurry 2021-08-16 19:58:03+00:00   \n",
       "3       1.354477e+18  Vincent72516869 2021-01-27 17:11:08+00:00   \n",
       "4       1.076943e+18     YoonJaysSimp 2018-12-23 20:50:49+00:00   \n",
       "...              ...              ...                       ...   \n",
       "573775  2.701354e+07       GhelSandra 2009-03-27 14:25:52+00:00   \n",
       "573776  1.418420e+18    lilithrising_ 2021-07-23 03:59:18+00:00   \n",
       "573777  3.303069e+09        CJMoss007 2015-08-01 07:03:17+00:00   \n",
       "573778  1.319471e+18      Jankem69420 2020-10-23 02:50:36+00:00   \n",
       "573779  4.194755e+09      mg_violette 2015-11-15 15:11:09+00:00   \n",
       "\n",
       "                                         user_description  \\\n",
       "0       young guy, varied interests. socialist. europe...   \n",
       "1       so fuck your rules man your favorite k2, avril...   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4       bl content * anime * manga * manhwa * nsfw * s...   \n",
       "...                                                   ...   \n",
       "573775  tomasino est 2000something art educator.person...   \n",
       "573776                                                NaN   \n",
       "573777                              #justiceforjohnnydepp   \n",
       "573778  ''virtue-signalling geopolitically ignorant ca...   \n",
       "573779  author of the saga \"the guardian angel of the ...   \n",
       "\n",
       "                                  user_description_tokens  \n",
       "0       [young, guy, varied, interests, socialist, eur...  \n",
       "1       [fuck, rules, favorite, k2, avril, lavigne, wo...  \n",
       "2                                                    None  \n",
       "3                                                    None  \n",
       "4       [bl, content, anime, manga, manhwa, nsfw, simm...  \n",
       "...                                                   ...  \n",
       "573775  [tomasino, 2000something, art, sayaka, akimoto...  \n",
       "573776                                               None  \n",
       "573777                             [justiceforjohnnydepp]  \n",
       "573778  [geopolitically, ignorant, cartoon, mouse, lam...  \n",
       "573779  [author, saga, guardian, angel, demon, book, a...  \n",
       "\n",
       "[573780 rows x 13 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_2022_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07f4bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_2022_prepared.to_csv(data_path+\"2022_prepared_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8418a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
